#!/usr/bin python
# -*- coding: utf-8 -*-

import sys
sys.path.append('/home/ilya/work/emcee')
import math
import emcee
import numpy as np
#import numdifftools as nd
from scipy import special
from scipy import optimize
#from knuth_hist import histogram
#from matplotlib.pyplot import bar, text, xlabel, ylabel, axvline, rc
from scipy.stats.kde import gaussian_kde


class LnPost(object):
    """
    Class that represents posterior density of parameters.
    Using ``detections`` and ``ulimits`` parameters find probability of them
    being generated from cross-to-parallel hands distribution generated
    by distributions of model parameters presented as ``distributions`` and
    other model parameters.
    """

    def __init__(self, detections, ulimits, distributions, size=None, lnpr=None,
                 args=None):
        self._lnpr = lnpr
        self.args = args
        self._lnlike = LnLike(detections, ulimits, distributions, size=size)

    def lnpr(self, p):
        return self._lnpr(p, *self.args)

    def lnlike(self, p):
        return self._lnlike.__call__(p)

    def __call__(self, p):
        return self.lnlike(p) + self.lnpr(p)


class LnLike(object):
    """
    Class representing Likelihood function.
    """

    def __init__(self, detections, ulimits, distributions, size=None):
        """
        Parameters:

            detections - values of cross-to-parallel hands ratios for the
                         detected cross-hands,

            ulimits - upper limits on cross-to-parallel hands ratios

            distributions - distributions of (|r|, |M|, fi_M, |D_2|, fi_2, fi_1).
                            or list of (callable, args, kwargs,)
            size - size of model distributions that will be used for estimating
                pdf of cross-to-parallel hands ratios for given other model
                parameters. If it is None then distributions is treated like
                several data samples taken from each distribution. If it is
                set then distribution is treated like list of tuples with
                callables and arguments.
        """

        self.detections = detections
        self.ulimits = ulimits
        self.size = size
        self.distributions = list()

        # Size of model distributions must be specified
        assert(self.size)

        for entry in distributions:
            entry[2].update({'size': self.size})
            self.distributions.append(_distribution_wrapper(entry[0],
                                                            entry[1], entry[2]))

    def __call__(self, p):
        """
        Returns lnlikelihood of detections and ulimits being generated from
        distributions generated by model with given models distributions and given
        d.
        """

        ratio_distribution = self.model(p)
        lnlk_detections = self.lnprob(self.detections, ratio_distribution)
        lnlk_ulimits = self.lnprob(self.ulimits, ratio_distribution, kind='u')

        lnlk = lnlk_detections + lnlk_ulimits

        print "LnLikelihood is: " + str(lnlk)

        return lnlk

    def model(self, p):
        """
        Method that given parameter vector returns pdf of cross-to-parallel
        hands ratios.

        Parameters:

            p - single walker

        Output:

            np.array of N values of cross-hand ratios.
        """

        data = self.distributions

        try:
            result = data[1]()[0, :] * np.exp(1j * data[2]()) + data[3]() *\
                     np.exp(1j * data[4]()) + p * np.exp(1j * data[5]())
        except IndexError:
            result = data[1]() * np.exp(1j * data[2]()) + data[3]() * np.exp(1j *\
                     data[4]()) + p * np.exp(1j * data[5]())

        return data[0]() * np.sqrt((result * np.conj(result)).real)

    def model_vectorized(self, p):
        """
        Method that given ensemble of walkers returns distributions of
        cross-to-parallel hands ratios.

        Parameters:

            p - ensemble of walkers

        Output:

            np.array of (N, len(self.distributions[i]) values of
            cross-to-parallel hand ratios.
        """

        return self.model(p[:, np.newaxis])

    def lnprob(self, xs, distribution, kind=None):
        """
        Method that given some values ``xs`` and sample from some distribution
        (container of values) returns natural logarithm of likelihood of values
        ``xs`` being generated from given distribution.

        Parameters:

            xs - values of interest,

            distribution - [container] - sample from distribution that is checked,

            kind [None, 'u', 'l'] - type of values ``xs`` (detections, upper or
            lower limits).

        Output:

        Natural logarithm of likelihood of ``xs`` being generated from
        sample's distribution.
        """

        kde = gaussian_kde(distribution)
        probs = np.zeros(len(xs))

        if kind is None:
            probs = kde(xs)
        elif kind is 'u':
            for i in range(len(probs)):
                probs[i] = kde.integrate_box_1d(min(distribution), xs[i])
        elif kind is 'l':
            raise NotImplementedError('Please, implement lower limits!')
        else:
            raise Exception('``kind`` parameter must be ``None``, ``u``\
                            or ``l``.')

        result = np.log(probs).sum()

        return result


class _distribution_wrapper(object):
    """
    This is a hack to make the distribution function picklable when ``args``
    and ``kwargs`` are also included.
    """

    def __init__(self, f, args, kwargs):
        self.f = f
        self.args = args
        self.kwargs = kwargs

    def __call__(self):
            try:
                return self.f(*self.args, **self.kwargs)
            except:
                import traceback
                print("mmcmc: Exception while calling your distribution callable:")
                print("  args:", self.args)
                print("  kwargs:", self.kwargs)
                print("  exception:")
                traceback.print_exc()
                raise


def lnunif(x, a, b):
    """
    (Natural logarithm of) uniform distribution on [a, b].
    """

    result = - math.log(b - a)
    if not (a <= x) & (x <= b):
        result = float('-inf')

    return result


def vec_lnunif(x, a, b):
    """
    Vectorized (natural logarithm of) uniform distribution on [a, b].
    """

    result1 = -np.log(b - a)
    result = np.where((a <= x) & (x <= b), result1, float('-inf'))

    return result


def vec_lnlognorm(x, mu, sigma):
    """
    Vectorized (natural logarithm of) LogNormal distribution.
    """

    x_ = np.where(0 < x, x, 1)
    result1 = -np.log(np.sqrt(2. * math.pi) * x_ * sigma) - (np.log(x_) - mu)\
        ** 2 / (2. * sigma ** 2)
    result = np.where(0 < x, result1, float("-inf"))

    return result


def vec_lngenbeta(x, alpha, beta, c, d):
    """
    Vectorized (natural logarithm of) Beta distribution with support (c,d). A.k.a.
    generalized Beta distribution.
    """

    x_ = np.where((c < x) & (x < d), x, 1)

    result1 = -math.log(special.beta(alpha, beta)) - (alpha + beta - 1.) *\
        math.log(d - c) + (alpha - 1.) * np.log(x_ - c) + (beta - 1.) *\
        np.log(d - x_)
    result = np.where((c < x) & (x < d), result1, float("-inf"))

    return result


def logp(x):
    """
    logPrior used in PT.
    """

    return lnunif(x, 0., 1.)


def percent(xs, perc=None):
    """
    Find ``perc`` % in sorted container xs.
    """

    xs_ = sorted(xs)
    indx = int(math.ceil(len(xs) * perc / 100.))

    return xs_[indx]


def genbeta(a, b, *args, **kwargs):
    return (b - a) * np.random.beta(*args, **kwargs) + a


def fn_distributions(mmin, mmax, dmin, dmax):

    return ((np.random.lognormal, list(), {'mean': 0.0, 'sigma': 0.25}),
            (genbeta, [mmin, mmax, 2.0, 3.0], dict(),),
            (np.random.uniform, list(), {'low': -math.pi, 'high': math.pi}),
            (genbeta, [dmin, dmax, 3.0, 8.0], dict(),),
            (np.random.uniform, list(), {'low': -math.pi, 'high': math.pi}),
            (np.random.uniform, list(), {'low': -math.pi, 'high': math.pi}))


def laplace_logevidence(lnpost):
    """
    Function that given ln of posterior pdf returns ln of evidence using Laplace
    approximation.
    """

    # Find MAP
    result = optimize.minimize_scalar(lambda x: -lnpost(x), bounds=[0.01, 0.25],
                                     method='Bounded')
    x_map = result['x']
    # Find Hessian at MAP
    hess = nd.Hessdiag(lnpost)
    hess_map = hess(x_map)

    try:
        M = len(x_map)
    except TypeError:
        M = 1
    print x_map
    print lnpost(x_map)
    print M
    print hess_map[0]
    return lnpost(x_map) + 0.5 * M * math.log(2 * math.pi) -\
           0.5 * np.log(abs(hess_map[0]))


def find_m(mmax, mmin=0, dmin=0, dmax=0.1, detections=None, ulimits=None):

    lnpost = LnPost(detections, ulimits,
                    fn_distributions(mmin, mmax, dmin, dmax),
                    size=10000, lnpr=lnunif, args=[0., 1.])

    return laplace_logevidence(lnpost)


if __name__ == '__main__()':

    # C band D_L
    detections = [0.143, 0.231, 0.077, 0.09, 0.152, 0.115, 0.1432, 0.1696, 0.1528,
                  0.126, 0.1126, 0.138, 0.194, 0.109, 0.101]
    ulimits = [0.175, 0.17, 0.17, 0.088, 0.187, 0.1643, 0.0876, 0.123, 0.77,
               0.057, 0.155]

    # Create data set from hypothetical parameters
    # Preparing distributions
    distributions = ((np.random.lognormal, list(),
                      {'mean': 0.0, 'sigma': 0.25}),
                     # zeropol
                     (genbeta, [0.0, 0.05, 1.0, 8.0],
                     dict(),),
                     # lowpol
                      #(genbeta, [0.0, 0.05, 2.0, 3.0],
                      #dict(),),
                       # highpol
                      #(genbeta, [0.05, 0.1, 2.0, 3.0],
                      # dict(),),
                      (np.random.uniform, list(),
                        {'low': -math.pi, 'high': math.pi}),
                      (genbeta, [0.01, 0.10, 3.0, 8.0], dict(),),
                      (np.random.uniform, list(),
                        {'low': -math.pi, 'high': math.pi}),
                      (np.random.uniform, list(),
                        {'low': -math.pi, 'high': math.pi}))

    # Sampling posterior density of ``p``

    # Prepare sample of D_RA values from hypothetical distribution:
    d_hypo = genbeta(0.09, 0.11, 5, 5, size=500)

    # Initialize LnPost class - we need methods of it's objects
    lnpost = LnPost(detections, ulimits, distributions, size=100,
                    lnpr=vec_lngenbeta, args=[5, 5, 0.08, 0.12])

    # 500 samples with 10000 data points each
    predictive_ratios = lnpost._lnlike.model_vectorized(d_hypo)
    # Create 500 data samples with 100 data points in each
    simulated_datas = [np.random.choice(ratio, size=100) for ratio in
                       predictive_ratios]

    # Or use kde
    from scipy.stats.kde import gaussian_kde
    kde = gaussian_kde(detections)
    newdets = kde.resample(size=1000)[0]

    # Now analize each data sample to find D_RA
    lnpost = LnPost(newdets, ulimits, distributions, size=10000,
                    lnpr=vec_lnunif, args=[0.0, 0.2])

    # Using affine-invariant MCMC
    nwalkers = 250
    ndim = 1
    p0 = np.random.uniform(low=0.0, high=0.2, size=(nwalkers, ndim))
    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnpost)
    pos, prob, state = sampler.run_mcmc(p0, 250)
    sampler.reset()

    sampler.run_mcmc(pos, 500)
